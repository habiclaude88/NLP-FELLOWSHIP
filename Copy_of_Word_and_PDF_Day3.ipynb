{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Working with Word Documents and PDFs\n",
        "\n",
        "In the African continent, most documents are in word or PDF. For the data in the documents to be processed and used in AI, they need to be extracted. To do this, the data will be extracted to txt format.\n",
        "\n"
      ],
      "metadata": {
        "id": "-1LUjCesZBKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Package\n",
        "The package to be used in textract.\n",
        "\n",
        "To install the package, use the commands below\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "apt-get install python-dev libxml2-dev libxslt1-dev antiword unrtf poppler-utils pstotext tesseract-ocr \\\n",
        "flac ffmpeg lame libmad0 libsox-fmt-mp3 sox libjpeg-dev swig\n",
        "\n",
        "pip install textract\n",
        "```\n",
        "\n",
        "The package supports a lot of formats including but not limmited:\n",
        "\n",
        "csv, doc, docx, epub,json, html,pdf, jpg, pptx, xls, xlsx, ogg \n",
        "\n"
      ],
      "metadata": {
        "id": "YhWTdFi4ebY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rTyZY41XgWwl",
        "outputId": "4a9301e1-d93f-455e-b29f-7b9495115691"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting textract\n",
            "  Downloading textract-1.6.5-py3-none-any.whl (23 kB)\n",
            "Collecting extract-msg<=0.29.*\n",
            "  Downloading extract_msg-0.28.7-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting six~=1.12.0\n",
            "  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting SpeechRecognition~=3.8.1\n",
            "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting docx2txt~=0.8\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "Collecting xlrd~=1.2.0\n",
            "  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 57.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from textract) (3.0.4)\n",
            "Collecting pdfminer.six==20191110\n",
            "  Downloading pdfminer.six-20191110-py2.py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 38.3 MB/s \n",
            "\u001b[?25hCollecting argcomplete~=1.10.0\n",
            "  Downloading argcomplete-1.10.3-py2.py3-none-any.whl (36 kB)\n",
            "Collecting python-pptx~=0.6.18\n",
            "  Downloading python-pptx-0.6.21.tar.gz (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 41.8 MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4~=4.8.0\n",
            "  Downloading beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 66.5 MB/s \n",
            "\u001b[?25hCollecting pycryptodome\n",
            "  Downloading pycryptodome-3.15.0-cp35-abi3-manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 64.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six==20191110->textract) (2.4.0)\n",
            "Collecting soupsieve>=1.2\n",
            "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
            "Collecting olefile>=0.46\n",
            "  Downloading olefile-0.46.zip (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 68.9 MB/s \n",
            "\u001b[?25hCollecting ebcdic>=1.1.1\n",
            "  Downloading ebcdic-1.1.1-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 32.7 MB/s \n",
            "\u001b[?25hCollecting imapclient==2.1.0\n",
            "  Downloading IMAPClient-2.1.0-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting tzlocal>=2.1\n",
            "  Downloading tzlocal-4.2-py3-none-any.whl (19 kB)\n",
            "Collecting compressed-rtf>=1.0.6\n",
            "  Downloading compressed_rtf-1.0.6.tar.gz (5.8 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from python-pptx~=0.6.18->textract) (4.9.1)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.7/dist-packages (from python-pptx~=0.6.18->textract) (7.1.2)\n",
            "Collecting XlsxWriter>=0.5.7\n",
            "  Downloading XlsxWriter-3.0.3-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 60.1 MB/s \n",
            "\u001b[?25hCollecting pytz-deprecation-shim\n",
            "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting backports.zoneinfo\n",
            "  Downloading backports.zoneinfo-0.2.1-cp37-cp37m-manylinux1_x86_64.whl (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting tzdata\n",
            "  Downloading tzdata-2022.5-py2.py3-none-any.whl (336 kB)\n",
            "\u001b[K     |████████████████████████████████| 336 kB 44.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: docx2txt, compressed-rtf, olefile, python-pptx\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3980 sha256=4ffcf6fcbe594bd3cf1109e54d567b78a77fc0ef1c08ed0597efd1e6a76a7cb6\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/20/b2/473e3aea9a0c0d3e7b2f7bd81d06d0794fec12752733d1f3a8\n",
            "  Building wheel for compressed-rtf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for compressed-rtf: filename=compressed_rtf-1.0.6-py3-none-any.whl size=6204 sha256=29bbff4ccea476e437f97b53a1c0d70f18bcf745937877f4e42df882105fb180\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/33/88/88ceee84d1b74b391c086bc594d3fcf80800decfbd6e1ff565\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35432 sha256=6c1d3dcd5786264ccc641891643050aa5fb4485c012b9a01be836e0ab36336a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/53/e6/37d90ccb3ad1a3ca98d2b17107e9fda401a7c541ea1eb6a65a\n",
            "  Building wheel for python-pptx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-pptx: filename=python_pptx-0.6.21-py3-none-any.whl size=470951 sha256=e8b4d294b8019d9808b5b8d5bb6a9c19f1a1b65ca2b239d265ad4729a740373f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/ab/f4/52560d0d4bd4055e9261c6df6e51c7b56c2b23cca3dee811a3\n",
            "Successfully built docx2txt compressed-rtf olefile python-pptx\n",
            "Installing collected packages: tzdata, backports.zoneinfo, six, pytz-deprecation-shim, XlsxWriter, tzlocal, soupsieve, pycryptodome, olefile, imapclient, ebcdic, compressed-rtf, xlrd, SpeechRecognition, python-pptx, pdfminer.six, extract-msg, docx2txt, beautifulsoup4, argcomplete, textract\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: tzlocal\n",
            "    Found existing installation: tzlocal 1.5.1\n",
            "    Uninstalling tzlocal-1.5.1:\n",
            "      Successfully uninstalled tzlocal-1.5.1\n",
            "  Attempting uninstall: xlrd\n",
            "    Found existing installation: xlrd 1.1.0\n",
            "    Uninstalling xlrd-1.1.0:\n",
            "      Successfully uninstalled xlrd-1.1.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "google-api-python-client 1.12.11 requires six<2dev,>=1.13.0, but you have six 1.12.0 which is incompatible.\n",
            "google-api-core 1.31.6 requires six>=1.13.0, but you have six 1.12.0 which is incompatible.\u001b[0m\n",
            "Successfully installed SpeechRecognition-3.8.1 XlsxWriter-3.0.3 argcomplete-1.10.3 backports.zoneinfo-0.2.1 beautifulsoup4-4.8.2 compressed-rtf-1.0.6 docx2txt-0.8 ebcdic-1.1.1 extract-msg-0.28.7 imapclient-2.1.0 olefile-0.46 pdfminer.six-20191110 pycryptodome-3.15.0 python-pptx-0.6.21 pytz-deprecation-shim-0.1.0.post0 six-1.12.0 soupsieve-2.3.2.post1 textract-1.6.5 tzdata-2022.5 tzlocal-4.2 xlrd-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRqsPyv-kOrn",
        "outputId": "d8caa124-905d-487d-b0dc-992a6ad24d60"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pypdf2\n",
            "  Downloading PyPDF2-2.11.1-py3-none-any.whl (220 kB)\n",
            "\u001b[K     |████████████████████████████████| 220 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from pypdf2) (4.1.1)\n",
            "Installing collected packages: pypdf2\n",
            "Successfully installed pypdf2-2.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Rx5KhiWzQVRQ"
      },
      "outputs": [],
      "source": [
        "import textract\n",
        "import os\n",
        "import PyPDF2 as pd2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We wil first mount the google drive. This will give us acces to my drive folder where we can find files"
      ],
      "metadata": {
        "id": "4n65qBvfljQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BKGVFNton6K",
        "outputId": "203c7c33-23dd-4a85-8fcf-0951b304d389"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Scan this path!'\n",
        "base_path = '/content/drive/MyDrive/ACTIVE LEARNING/NLP-DOC/'\n",
        "doc_dir = os.listdir(base_path)"
      ],
      "metadata": {
        "id": "62GwKNxqAmnJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_YLmDmprtaq",
        "outputId": "5b63593a-c27d-4da1-9231-0a11954f3785"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hansard Report - Wednesday, 12th October 2022 (A).pdf',\n",
              " 'Hansard Report - Thursday 6th October 2022 (P).pdf',\n",
              " 'Hansard Report - Thursday, 13th October 2022 (P).pdf',\n",
              " 'Hansard Report - Tuesday, 11th October 2022 (P).pdf',\n",
              " 'Hansard Report - Wednesday, 12th October 2022 (P)_0.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = pd2.PdfFileReader(base_path+\"Hansard Report - Wednesday, 12th October 2022 (A).pdf\")"
      ],
      "metadata": {
        "id": "eCwpxG9UsUq_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file.getNumPages()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcnkwK2puE-W",
        "outputId": "4635b23d-f4df-4d1d-fd03-98b659880cb0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file.getPage(0)"
      ],
      "metadata": {
        "id": "SzTn1H8DuYm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_pages(path, page_remove):\n",
        "  file_original = pd2.PdfFileReader(path)    #Open the Original file containing all the pages\n",
        "  last_page = file_original.getNumPages()-1\n",
        "  file_new = pd2.PdfFileWriter()\n",
        "  #page_remove = [1,4,6,7]\n",
        "  for page_number in range(1, last_page):\n",
        "    if page_number in page_remove:\n",
        "      pass\n",
        "    else:\n",
        "      page_content = file_original.getPage(page_number)\n",
        "      file_new.add_page(page_content)\n",
        "  return file_new\n"
      ],
      "metadata": {
        "id": "W5eLOl-ZsFTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_pages(path):\n",
        "  file_original = pd2.PdfFileReader(path)    #Open the Original file containing all the pages\n",
        "  last_page = file_original.getNumPages()-1\n",
        "  file_new = pd2.PdfFileWriter()\n",
        "  for page_number in range(1, last_page):\n",
        "    page_content = file_original.getPage(page_number)\n",
        "    file_new.add_page(page_content)\n",
        "  return file_new"
      ],
      "metadata": {
        "id": "S4vH1Z6Rx9L_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = drop_pages(base_path+\"Hansard Report - Wednesday, 12th October 2022 (A).pdf\")"
      ],
      "metadata": {
        "id": "QHTJ2Dt5yLiT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.getNumPages()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAssug-PyebU",
        "outputId": "b9ffd539-80e6-4302-83bd-55d7f4139ff3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#A funciton to save the file\n",
        "def save(name, file):\n",
        "  outputfilename = \"/content/temp/\" + name  #construct the path and filename\n",
        "  with open(outputfilename, 'wb') as output:\n",
        "    file.write(output)\n"
      ],
      "metadata": {
        "id": "UpWn_S7BytBW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save('Test_1.pdf', test)"
      ],
      "metadata": {
        "id": "1mAkd5NA0SLe"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8PscHHI24qJ",
        "outputId": "86018aad-cad9-40b4-9a6c-a7dad9247943"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hansard Report - Wednesday, 12th October 2022 (A).pdf',\n",
              " 'Hansard Report - Thursday 6th October 2022 (P).pdf',\n",
              " 'Hansard Report - Thursday, 13th October 2022 (P).pdf',\n",
              " 'Hansard Report - Tuesday, 11th October 2022 (P).pdf',\n",
              " 'Hansard Report - Wednesday, 12th October 2022 (P)_0.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for obj  in doc_dir:\n",
        "  file_new = drop_pages(base_path+obj)\n",
        "  save(obj, file_new)"
      ],
      "metadata": {
        "id": "rethGIGd2e2h"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}