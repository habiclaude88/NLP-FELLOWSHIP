{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF\n",
        "TF-IDF stands for Term Frequency, Inverse Document Frequency\n",
        "\n",
        "Steps:\n",
        "\n",
        "\n",
        "*   Create a dict which will have the frequency of the token in the whole text\n",
        "*   Create a dict with token and index\n",
        "* Create a dict with token and idf calculated log(number_of_sentences/frequency_of_word)\n",
        "* Create dict with tokens and average frequency\n",
        "* Get the tf-idf by af*idf\n",
        "* Add to the vector\n",
        "\n"
      ],
      "metadata": {
        "id": "GKBPXAJPbGnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math"
      ],
      "metadata": {
        "id": "qNgKppbDgt_3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_sentences = ['this is a list of sentences', 'second sentence in list of sentences', 'a word for complexity']\n",
        "word_to_index = {}\n",
        "index_to_word = {}\n",
        "idf = {}\n",
        "num_documents = 0\n",
        "\n",
        "num_documents = len(list_sentences)\n",
        "\n",
        "global_term_freq = {}\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DYcZmlelDRIO"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "h3Nxt31yZF4d"
      },
      "outputs": [],
      "source": [
        "data = ['this is a list of sentences', 'second sentence in list of sentences', 'a word for complexity']\n",
        "word_to_index = {}\n",
        "index_to_word = {}\n",
        "idf = {}\n",
        "num_documents = 0\n",
        "\n",
        "num_documents = len(data)\n",
        "\n",
        "global_term_freq = {}\n",
        "list_sentences = data\n",
        "\n",
        "# Create dict with token and frequency in the whole text\n",
        "for sentence in list_sentences:\n",
        "    words_in_sent = set()\n",
        "\n",
        "    word_dict ={}\n",
        "    words = [token for token in sentence.split() ]\n",
        "\n",
        "    # frequency in this sentence\n",
        "    for word in words:\n",
        "        word_dict[word] = word_dict.get(word,0)+1\n",
        "\n",
        "    for word in word_dict:\n",
        "        global_term_freq[word] = global_term_freq.get(word,0)+1 # getting frequency in all dataset\n",
        "            \n",
        "\n",
        "\n",
        "\n",
        "for word, frequency in global_term_freq.items():\n",
        "        idf_value = math.log((1+num_documents)/(1+frequency))\n",
        "        \n",
        "        idf[word] = idf_value\n",
        "        \n",
        "        document_words = list(global_term_freq.keys())\n",
        "        for word_position in range(len(document_words)):\n",
        "            word = document_words[word_position]\n",
        "            word_to_index[word] = word_position\n",
        "            index_to_word[word_position] = word\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FONx4ZUSJMmS",
        "outputId": "47ee5f62-2676-4c45-e3d7-7985fa403105"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'this': 0.6931471805599453,\n",
              " 'is': 0.6931471805599453,\n",
              " 'a': 0.28768207245178085,\n",
              " 'list': 0.28768207245178085,\n",
              " 'of': 0.28768207245178085,\n",
              " 'sentences': 0.28768207245178085,\n",
              " 'second': 0.6931471805599453,\n",
              " 'sentence': 0.6931471805599453,\n",
              " 'in': 0.6931471805599453,\n",
              " 'word': 0.6931471805599453,\n",
              " 'for': 0.6931471805599453,\n",
              " 'complexity': 0.6931471805599453}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_arrays = []\n",
        "data = ['which will have the frequency of the token in the whole text']\n",
        "for sent in data:\n",
        "  tokens = [token for token in sent.split()]\n",
        "\n",
        "  word_array = np.zeros(len(word_to_index))\n",
        "  \n",
        "  sentence_tf_idf = {}\n",
        "  # Gets the document frequency by using the helper method\n",
        "  \n",
        "  document_frequency ={}\n",
        "  \n",
        "\n",
        "  for word in tokens:\n",
        "      document_frequency[word] = document_frequency.get(word,0)+1\n",
        "  # Gets the total number of words in sentence\n",
        "  total_words = sum(document_frequency.values())\n",
        "  # Find individual term frequency value averaged by total number of words.\n",
        "  \n",
        "  averaged_frequency = {k:(float(v)/total_words) for k,v in document_frequency.items()}\n",
        "  \n",
        "  for term, tf in averaged_frequency.items():\n",
        "      # Out of vocabulary words are simply zeroed. They are going to be removed later either way.\n",
        "      # Computes the tfidf for each word by using word tf times the term idf\n",
        "      sentence_tf_idf[term] = tf*idf.get(term, 0)\n",
        "  \n",
        "  for token in tokens:\n",
        "      if token in word_to_index:\n",
        "          token_index = word_to_index[token]\n",
        "          # Add the tfidf value for each token in sentence to its position in vocabulary array.\n",
        "          word_array[token_index] = sentence_tf_idf[token]\n",
        "  \n",
        "  sentence_arrays.append(word_array)\n",
        "\n",
        "transformed_matrx = np.matrix(sentence_arrays)\n",
        "print(transformed_matrx)\n",
        "print(word_to_index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTYEPG6Wgd2H",
        "outputId": "8e8f665c-e2bb-4b9f-9d57-247e8f962316"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         0.         0.02397351 0.\n",
            "  0.         0.         0.05776227 0.         0.         0.        ]]\n",
            "{'this': 0, 'is': 1, 'a': 2, 'list': 3, 'of': 4, 'sentences': 5, 'second': 6, 'sentence': 7, 'in': 8, 'word': 9, 'for': 10, 'complexity': 11}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fbpt6gX9mg8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In-class practicals\n",
        "Create a class using code above"
      ],
      "metadata": {
        "id": "wRPi3qszPPkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TDIDF:\n",
        "    def __init__(self):\n",
        "        \n",
        "        self.word_to_index = {}\n",
        "        self.index_to_word = {}\n",
        "        self.idf = {}\n",
        "        self.num_documents = 0\n",
        "        \n",
        "\n",
        "    def term_frequency(self,sentence):\n",
        "       \n",
        "        return word_dict\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        # Enter code here. It will involve getting the idf and the word_to_index. Returns nothing\n",
        "\n",
        "    def transform(self, data):\n",
        "        if isinstance(data,list):\n",
        "            return self._transform_document(data)\n",
        "        elif isinstance(data,str):\n",
        "            return self._tranform_sentence(data)\n",
        "\n",
        "    def _transform_document(self,data):\n",
        "        #used for processing multiple sentences\n",
        "       \n",
        "\n",
        "        return np.matrix(sentence_arrays)\n",
        "\n",
        "    def _tranform_sentence(self,data):\n",
        "        # given a sentence get the average frequency and multiply it with the idf. Then place the values in the word array\n",
        "        return word_array\n",
        "\n",
        "    def _compute_sentence_tf_idf(self, sentence):\n",
        "        \"\"\"\n",
        "        Computes the tf_idf for a single sentence(document).\n",
        "        \"\"\"\n",
        "        # sentence_tf_idf = {}\n",
        "        # # Gets the document frequency by using the helper method\n",
        "        # document_frequency = self.term_frequency(sentence, self.ignore_tokens, self.lower_case)\n",
        "        # # Gets the total number of words in sentence\n",
        "        # total_words = sum(document_frequency.values())\n",
        "        # # Find individual term frequency value averaged by total number of words.\n",
        "        # averaged_frequency = {k:(float(v)/total_words) for k,v in document_frequency.items()}\n",
        "        \n",
        "        # for term, tf in averaged_frequency.items():\n",
        "        #     # Out of vocabulary words are simply zeroed. They are going to be removed later either way.\n",
        "        #     # Computes the tfidf for each word by using word tf times the term idf\n",
        "        #     sentence_tf_idf[term] = tf*self.idf.get(term, 0)\n",
        "        return sentence_tf_idf"
      ],
      "metadata": {
        "id": "V54YjIZcPYHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing your code\n",
        "tdidf = TDIDF()\n",
        "tdidf.fit(['this is a list of sentences', 'second sentence in list of sentences', 'a word for complexity'])\n",
        "print(tdidf.word_to_index)\n",
        "print(tdidf.idf)\n",
        "print(tdidf.transform(\"this is a sentence with two words sentence in\")) # it should pick either sentence or array of sentences"
      ],
      "metadata": {
        "id": "i-TaxVQeQ16R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment\n",
        "\n",
        "\n",
        "*   Compare results with sklearn package: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
        "*   Use the code above on the cleaned text\n",
        "\n"
      ],
      "metadata": {
        "id": "hPsYthOFRTIJ"
      }
    }
  ]
}