{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup as bs\n",
        "import requests\n",
        "import re\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "nSr93EWcKPfi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "1Rt-ETPbKS0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ASSIGNMENT I**: creating a new json file"
      ],
      "metadata": {
        "id": "e9q11VdXJ8V-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://dummyjson.com/products\""
      ],
      "metadata": {
        "id": "ARTAxuPHKJIE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = requests.get(url).json()"
      ],
      "metadata": {
        "id": "u1Mv2k1gYi8d"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "products = data[\"products\"]\n"
      ],
      "metadata": {
        "id": "FL0FnRzNYvMn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GET LAST 20 PRODUCTS\n",
        "last_20Products = products[-20:]"
      ],
      "metadata": {
        "id": "X2c--McBYbZi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATE AGGREGATE JSON  "
      ],
      "metadata": {
        "id": "MIkf_8cOZSiZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_json = {}"
      ],
      "metadata": {
        "id": "Jregi8wAZ0vl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[new_json.setdefault(prod[\"category\"],[{}]) for prod in products if prod[\"category\"] not in list(new_json.keys())]"
      ],
      "metadata": {
        "id": "frKb3BgiZdLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_json"
      ],
      "metadata": {
        "id": "YWSDLSEQcL_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for category in list(new_json.keys()):\n",
        "  for product in products:\n",
        "    if product[\"category\"] == category:\n",
        "      try:\n",
        "        new_json[category][0][product[\"brand\"]].insert(0,product[\"title\"])\n",
        "        # ADD PRICE AND NUMBER OF ITEMS\n",
        "        new_json[category][0][product[\"brand\"]][-2] += product['price']\n",
        "        new_json[category][0][product[\"brand\"]][-1] += 1\n",
        "        # MAKE AVERAGE PRICE\n",
        "        new_json[category][0][product[\"brand\"]][-2] = round((float(new_json[category][0][product[\"brand\"]][-2]) / new_json[category][0][product[\"brand\"]][-1]),1)\n",
        "\n",
        "      except KeyError:\n",
        "        new_json[category][0][product[\"brand\"]] = [0,0]\n",
        "        new_json[category][0][product[\"brand\"]].insert(0,product[\"title\"])\n",
        "        # ADD PRICE AND NUMBER OF ITEMS\n",
        "        new_json[category][0][product[\"brand\"]][-2] += product['price']\n",
        "        new_json[category][0][product[\"brand\"]][-1] += 1\n",
        "        # MAKE AVERAGE PRICE\n",
        "        new_json[category][0][product[\"brand\"]][-2] = round((float(new_json[category][0][product[\"brand\"]][-2]) / new_json[category][0][product[\"brand\"]][-1]),1)"
      ],
      "metadata": {
        "id": "-S_B07_RbQMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# REMOVE THE NUMBER REPESENT ITEMS IN A CATEGORY\n",
        "for category in list(new_json.keys()):\n",
        "  for brand in list(new_json[category][0].keys()):\n",
        "    new_json[category][0][brand].pop()\n"
      ],
      "metadata": {
        "id": "2Hg_qgHYh_mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgdqPD1gfdea",
        "outputId": "252f5e7a-d683-4e9b-afed-e65edc8bbdb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'smartphones': [{'Apple': ['iPhone X', 'iPhone 9', 724.0],\n",
              "   'Samsung': ['Samsung Universe 9', 1249.0],\n",
              "   'OPPO': ['OPPOF19', 280.0],\n",
              "   'Huawei': ['Huawei P30', 499.0]}],\n",
              " 'laptops': [{'APPle': ['MacBook Pro', 1749.0],\n",
              "   'Samsung': ['Samsung Galaxy Book', 1499.0],\n",
              "   'Microsoft Surface': ['Microsoft Surface Laptop 4', 1499.0],\n",
              "   'Infinix': ['Infinix INBOOK', 1099.0],\n",
              "   'HP Pavilion': ['HP Pavilion 15-DK1056WM', 1099.0]}],\n",
              " 'fragrances': [{'Impression of Acqua Di Gio': ['perfume Oil', 13.0],\n",
              "   'Royal_Mirage': ['Brown Perfume', 40.0],\n",
              "   'Fog Scent Xpressio': ['Fog Scent Xpressio Perfume', 13.0],\n",
              "   'Al Munakh': ['Non-Alcoholic Concentrated Perfume Oil', 120.0],\n",
              "   'Lord - Al-Rehab': ['Eau De Perfume Spray', 30.0]}],\n",
              " 'skincare': [{\"L'Oreal Paris\": ['Hyaluronic Acid Serum', 19.0],\n",
              "   'Hemani Tea': ['Tree Oil 30ml', 12.0],\n",
              "   'Dermive': ['Oil Free Moisturizer 100ml', 40.0],\n",
              "   'ROREC White Rice': ['Skin Beauty Serum.', 46.0],\n",
              "   'Fair & Clear': ['Freckle Treatment Cream- 15gm', 70.0]}],\n",
              " 'groceries': [{'Saaf & Khaas': ['- Daal Masoor 500 grams', 20.0],\n",
              "   'Bake Parlor Big': ['Elbow Macaroni - 400 gm', 14.0],\n",
              "   'Baking Food Items': ['Orange Essence Food Flavou', 14.0],\n",
              "   'fauji': ['cereals muesli fruit nuts', 46.0],\n",
              "   'Dry Rose': ['Gulab Powder 50 Gram', 70.0]}],\n",
              " 'home-decoration': [{'Boho Decor': ['Plant Hanger For Home', 41.0],\n",
              "   'Flying Wooden': ['Flying Wooden Bird', 51.0],\n",
              "   'LED Lights': ['3D Embellishment Art Lamp', 20.0],\n",
              "   'luxury palace': ['Handcraft Chinese style', 60.0],\n",
              "   'Golden': ['Key Holder', 30.0]}]}"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ASSIGNMENT II** : scrap igihe.com from January to present"
      ],
      "metadata": {
        "id": "07W3ZYr0bF39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unsortedLinks = []\n",
        "\n",
        "for month in range(1, 11):\n",
        "  for day in range(1, 32):\n",
        "    l = \"http://archive.org/wayback/available?url=igihe.com&timestamp=2022{:02d}{:02d}\".format(month, day)\n",
        "    response = requests.get(l).json()\n",
        "    if  response['archived_snapshots']:\n",
        "      unsortedLinks.append(response['archived_snapshots']['closest'][\"url\"])"
      ],
      "metadata": {
        "id": "uAeHmrCaRE9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(unsortedLinks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wazMetsxUIXE",
        "outputId": "7380ecad-579a-4438-8144-4efb97f94548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "307"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array(unsortedLinks)\n",
        "series = pd.Series(arr)\n",
        "unsortedLinks = series.unique()"
      ],
      "metadata": {
        "id": "aaObZfxtV7y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "serious_links = {}\n"
      ],
      "metadata": {
        "id": "9SVdzehDhrCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# link = \"https://web.archive.org/web/20220615035616/https://www.igihe.com/amakuru/\"\n",
        "def process_links(link):\n",
        "  page = requests.get(link)\n",
        "  soup = bs(page.text, \"html.parser\")\n",
        "  \n",
        "  b = soup.body\n",
        "  get_titles = [link+re.sub(\"amakuru/\",\"\", a['href']) for span in b.find_all(\"span\", class_ = \"homenews-title\") for a in span.find_all(\"a\")]\n",
        "  \n",
        "  # get only links whose date is in current year\n",
        "  pattern = re.compile(r\"\\d{8,}?\")\n",
        "  found_date = pattern.search(link).group()\n",
        "  if found_date[3] != str(2):\n",
        "    pass\n",
        "  else:\n",
        "    file_title = f\"igihe-{found_date[0:4]}-{found_date[4:6]}-{found_date[6:8]}\"\n",
        "    try:\n",
        "      for title in get_titles:\n",
        "        serious_links[file_title].append(title)\n",
        "    except KeyError:\n",
        "      serious_links[file_title] = []\n",
        "      for title in get_titles:\n",
        "        serious_links[file_title].append(title)"
      ],
      "metadata": {
        "id": "RWBqtAaGnqEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for link in unsortedLinks:\n",
        "  process_links(link)"
      ],
      "metadata": {
        "id": "vN79F78QK76k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "serious_links"
      ],
      "metadata": {
        "id": "-H6yZC9fMRQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def writeToFile(paragraphs, file):\n",
        "  with open(file, \"a+\") as f:\n",
        "    for line in paragraphs:\n",
        "      f.write(line)"
      ],
      "metadata": {
        "id": "3tAWz2wTOIPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_page():\n",
        "  count = 1\n",
        "  for key in list(serious_links.keys()):\n",
        "    for link in set(serious_links[key]):\n",
        "      p = requests.get(link).content\n",
        "      soup = bs(p, \"html.parser\")\n",
        "      spans = soup.find_all(\"div\", class_= \"fulltext margintop10\")\n",
        "      paragraphs = [p.get_text() for span in spans for p in span.find_all(\"p\")]\n",
        "      writeToFile(paragraphs = paragraphs, file = f\"/content/drive/MyDrive/NLP fellowship/week1 tasks/{key}.txt\")\n",
        "    print(f\"file {count} created\")\n",
        "    count += 1"
      ],
      "metadata": {
        "id": "modd8RmbpQNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FINISH THE PROGRAM\n",
        "get_page()"
      ],
      "metadata": {
        "id": "TndWvTTCmqer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lEGujr-Xe6_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ASSIGNMENT III** : extract text from 5 pdf documents provided and write them in a single file"
      ],
      "metadata": {
        "id": "UDxjrVRtesoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textract\n"
      ],
      "metadata": {
        "id": "OA5HWiBJfQw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "tsVTYRoC29Xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " import os\n",
        " import textract, PyPDF2"
      ],
      "metadata": {
        "id": "fziP5lcSejM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_iyEaB8WQa1",
        "outputId": "ce1f1472-763f-4ca3-f948-77d055c500ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GET THE PDF FILES \n",
        "os.chdir(\"/content/drive/MyDrive/NLP fellowship/files\")\n",
        "PDFs = [file for file in os.listdir() if \"Hansard\" in file]"
      ],
      "metadata": {
        "id": "qOHGZ-9_fhBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PDFs"
      ],
      "metadata": {
        "id": "A7cdsT8DgPXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_firstPage(pdfs):\n",
        "  pages = {}\n",
        "  temp = PyPDF2.PdfFileWriter()\n",
        "  for pdf in pdfs:\n",
        "    pages[pdf] = []\n",
        "\n",
        "  for pdf in pdfs:\n",
        "    reader = PyPDF2.PdfFileReader(pdf)\n",
        "    allowed_pages = reader.getNumPages()\n",
        "    for page_number in range(1, allowed_pages-1):\n",
        "      # pages[pdf].append(reader.getPage(page_number))\n",
        "      temp.add_page(reader.getPage(page_number))\n",
        "\n",
        "  return temp\n"
      ],
      "metadata": {
        "id": "pC2dmiUnw8T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages = remove_firstPage(PDFs)"
      ],
      "metadata": {
        "id": "YLwh-O-2CQXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create template pdf file\n",
        "with open(\"/content/temp.pdf\", \"wb\") as f:\n",
        "  pages.write(f)"
      ],
      "metadata": {
        "id": "pXa92L616VZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EXTRACT EACH PDF\n",
        "def extract(file, new_destination = \"PDFsExtracted.txt\"):\n",
        "  text = textract.process(file).decode(\"utf-8\")\n",
        "  lines = text.split(\"\\n\")\n",
        "  with open(new_destination, \"a+\") as f:\n",
        "    for line in lines:\n",
        "      if line.strip():\n",
        "        f.write(line+\"\\n\")\n",
        "  with open(new_destination, \"a+\") as f:\n",
        "    f.write(\"\\n\")\n",
        "  \n",
        "extract(\"/content/temp.pdf\")"
      ],
      "metadata": {
        "id": "ftNithcygVnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**END OF THE WEEK ASSIGNMENT** data cleaning "
      ],
      "metadata": {
        "id": "7WUNVRRAgJpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "engKinyFile = \"/content/drive/MyDrive/NLP fellowship/week1 tasks/Eng_Kin-Paralleldata (1).csv\" "
      ],
      "metadata": {
        "id": "e_KHGfRRgTVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# READ THE FILE\n",
        "df = pd.read_csv(engKinyFile)\n",
        "kiny = df['Kinyarwanda']\n",
        "eng = df[\"English\"]"
      ],
      "metadata": {
        "id": "whfkAuSziGan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kiny"
      ],
      "metadata": {
        "id": "fvQjroVIzypn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NORMALIZING THE FILE\n",
        "kiny = kiny.str.lower()\n",
        "eng = eng.str.lower()"
      ],
      "metadata": {
        "id": "nOw2g9BUirv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# REMOVE THE WHITE SPACES\n",
        "kiny = kiny.str.strip()\n",
        "eng = eng.str.strip()"
      ],
      "metadata": {
        "id": "CrGmwqYRjvBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(kiny)"
      ],
      "metadata": {
        "id": "T00P3ERVxf1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kiny_list = list(kiny)\n",
        "eng_list = list(eng)"
      ],
      "metadata": {
        "id": "wuiZRc4l6mX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kiny_list"
      ],
      "metadata": {
        "id": "RZIdOIvrxai4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# REMOVE URLs and EMAILS\n",
        "pattern = re.compile(\"\\w+@[^\\s\\.]{3,}|([a-z]+\\.[\\w]{3,})|([^\\s]+(\\.net|\\.org|\\.com))|www\\..*|htt\\.*|[^\\s]+@[^\\s]+\")\n",
        "found = [pattern.findall(line) for line in eng_list if pattern.findall(line)]\n",
        "EngNo_urls = [pattern.sub(\"\",line) for line in eng_list]\n",
        "KinyNo_urls = [pattern.sub(\"\",line) for line in kiny_list]"
      ],
      "metadata": {
        "id": "eInuwLMwjTc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EngNo_urls\n",
        "found\n",
        "# KinyNo_urls"
      ],
      "metadata": {
        "id": "2FnbIizoD0df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# REMOVE PANCTUATIONS \n",
        "panc_pattern = re.compile(\"[^\\w\\s]+\")\n",
        "EngNo_punc = [panc_pattern.sub(\"\", line) for line in EngNo_urls]\n",
        "KinyNo_punc = [panc_pattern.sub(\"\", line) for line in KinyNo_urls]"
      ],
      "metadata": {
        "id": "_79gSrgJ53wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KinyNo_punc"
      ],
      "metadata": {
        "id": "Q1yilcXQ7c-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# REMOVE NUMBERS\n",
        "dig_pattern = re.compile(\"\\d+\")\n",
        "EngNo_dig = [dig_pattern.sub(\"\", line) for line in EngNo_punc]\n",
        "KinyNo_dig = [dig_pattern.sub(\"\", line) for line in KinyNo_punc]"
      ],
      "metadata": {
        "id": "j0UZFNzr_Aui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KinyNo_dig"
      ],
      "metadata": {
        "id": "U2GCqFh3_bZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove english words in kinyarwanda\n",
        "# eng_pattern = re.compile(\"\\w+[b-df-hj-np-tv-xz]\\b\")\n",
        "eng_pattern = re.compile(r\"\\w+[b-df-hj-np-tv-xz]\\b\")\n",
        "pure_kiny = [eng_pattern.sub(\"\",line) for line in KinyNo_dig ]"
      ],
      "metadata": {
        "id": "hQol5wlU4hs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pure_kiny"
      ],
      "metadata": {
        "id": "c929yV9V5fi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OUTPUT DATA\n",
        "df['Kinyarwanda'] = pd.DataFrame(pure_kiny)\n",
        "df[\"English\"] = pd.DataFrame(EngNo_dig)"
      ],
      "metadata": {
        "id": "yxde1wfoSoQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(30)"
      ],
      "metadata": {
        "id": "735H3ttPTSbS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}